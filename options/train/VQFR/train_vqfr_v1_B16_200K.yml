# general settings
name: train_vqfr_v1_B16_200K
model_type: VQFRModel
num_gpu: auto
manual_seed: 0
syncbn: true # must set to true to avoid bn inplace revision

datasets:
  train:
    name: FFHQ
    type: FFHQDegradationDataset
    dataroot_gt: datasets/ffhq/ffhq_512
    io_backend:
      type: disk
    use_hflip: true
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]
    out_size: 512
    blur_kernel_size: 41
    kernel_list: ['iso', 'aniso']
    kernel_prob: [0.5, 0.5]
    blur_sigma: [0.1, 10]
    downsample_range: [0.8, 8]
    noise_range: [0, 20]
    jpeg_range: [60, 100]
    use_shuffle: true
    num_worker_per_gpu: 6
    batch_size_per_gpu: 2
    dataset_enlarge_ratio: 1
    prefetch_mode: ~

  val:
    # Please modify accordingly to use your own validation
    # Or comment the val block if do not need validation during training
    name: validation
    type: PairedImageDataset
    dataroot_lq: datasets/Validation/SR_Validation
    dataroot_gt: datasets/Validation/SR_Validation
    io_backend:
      type: disk
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]
    scale: 1

# network structures
network_sr:
  type: VQFRv1
  base_channels: 128
  proj_patch_size: 32
  resolution_scale_rates: [ 1,2,2,2,2,2 ]
  channel_multipliers: [ 1,1,2,2,2,4 ]
  encoder_num_blocks: 2
  decoder_num_blocks: 3
  quant_level: [ 'Level_32' ]
  fix_keys: ['embedding']
  inpfeat_extraction_opt:
    in_dim: 3
    out_dim: 32
  align_from_patch: 32
  align_opt:
    Level_32:
      cond_channels: 32
      cond_downscale_rate: 32
      deformable_groups: 4
    Level_16:
      cond_channels: 32
      cond_downscale_rate: 16
      deformable_groups: 4
    Level_8:
      cond_channels: 32
      cond_downscale_rate: 8
      deformable_groups: 4
    Level_4:
      cond_channels: 32
      cond_downscale_rate: 4
      deformable_groups: 4
    Level_2:
      cond_channels: 32
      cond_downscale_rate: 2
      deformable_groups: 4
    Level_1:
      cond_channels: 32
      cond_downscale_rate: 1
      deformable_groups: 4
  quantizer_opt:
    Level_32:
      type: L2VectorQuantizerKmeans
      in_dim: 512
      num_code: 1024
      code_dim: 256
      reservoir_size: 16384
      reestimate_iters: 2000
      reestimate_maxiters: -1
      warmup_iters: -1

# network structures
network_g:
  type: VQGAN
  base_channels: 128
  proj_patch_size: 32
  resolution_scale_rates: [ 1,2,2,2,2,2 ]
  channel_multipliers: [ 1,1,2,2,2,4 ]
  encoder_num_blocks: 2
  decoder_num_blocks: 3
  quant_level: [ 'Level_32' ]
  quantizer_opt:
    Level_32:
      type: L2VectorQuantizer
      in_dim: 512
      num_code: 1024
      code_dim: 256
      reservoir_size: 16384
      reestimate_iters: 2000
      reestimate_maxiters: -1
      warmup_iters: -1

network_d_global:
  type: SWADiscriminator
  out_size: 512
  channel_multiplier: 2
  resample_kernel: [1, 3, 3, 1]

network_d_local:
  type: NLayerDiscriminator
  input_nc: 3
  ndf: 64
  n_layers: 3

network_d_main_global:
  type: SWADiscriminator
  out_size: 512
  channel_multiplier: 2
  resample_kernel: [1, 3, 3, 1]

network_d_main_local:
  type: NLayerDiscriminator
  input_nc: 3
  ndf: 64
  n_layers: 3

# path
path:
  pretrain_network_g: experiments/pretrained_models/VQ_Codebook_FFHQ512-39165968.pth
  param_key_g: params
  strict_load_g: ~
  pretrain_network_sr: experiments/pretrained_models/VQ_Codebook_FFHQ512-39165968.pth
  param_key_sr: params
  strict_load_sr: false
  pretrain_network_d_main_local:
  pretrain_network_d_main_global:
  pretrain_network_d_global:
  pretrain_network_d_local:
  resume_state: ~
  ignore_resume_networks: [ 'network_g' ]

# training settings
train:
  optim_sr:
    type: Adam
    lr: !!float 1e-5
    weight_decay: 0
    betas: [ 0.5, 0.9 ] # align with taming

  optim_d:
    type: Adam
    lr: !!float 1e-5
    weight_decay: 0
    betas: [ 0.5, 0.9]

  scheduler:
    type: MultiStepLR
    milestones: [ 200000 ]
    gamma: 1.0

  total_iter: 200000
  warmup_iter: -1  # no warm up

  pixel_opt:
    type: L1Loss
    loss_weight: !!float 1.0
    reduction: mean

  pixel_main_opt:
    type: L1Loss
    loss_weight: !!float 0.0
    reduction: mean

  latent_opt:
    type: MultiQuantMatchLoss
    Level_32:
      type: MSELoss
      loss_weight: !!float 1.0
      reduction: mean

  perceptual_opt:
    type: LPIPS
    perceptual_weight: 1.0
    style_weight: 2000.0
    style_measure: L1

  # losses
  global_gan_opt:
    type: GANLoss
    gan_type: wgan_softplus
    loss_weight: !!float 1.0

  patch_gan_opt:
    type: GANLoss
    gan_type: hinge
    loss_weight: !!float 1.0

  generator_d_global_weight: 0.5
  generator_d_local_weight: 0.5

  r1_reg_weight: 10
  net_d_reg_every: 16

  gan_start_iter: -1
  main_gan_start_iter: 5000

# validation settings
val:
  val_freq: !!float 5e3
  save_img: true
  test_which: main_branch
  metrics:
    psnr: # metric name, can be arbitrary
      type: calculate_psnr
      crop_border: 0
      test_y_channel: false

# logging settings
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

# dist training settings
dist_params:
  backend: nccl
  port: 29500
